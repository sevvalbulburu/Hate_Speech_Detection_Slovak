{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU devices found: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Current GPU device: /device:GPU:0\n",
      "TensorFlow is built with CUDA support (GPU acceleration).\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-09 15:36:21.783562: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-09 15:36:21.838010: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-09 15:36:21.838159: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-09 15:36:21.840065: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-09 15:36:21.840281: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-09 15:36:21.840375: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-09 15:36:21.882168: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-09 15:36:21.882292: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-09 15:36:21.882375: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-09 15:36:21.882438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 2284 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Check if TensorFlow can access any GPU devices\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if len(gpu_devices) == 0:\n",
    "    print(\"No GPU devices found.\")\n",
    "else:\n",
    "    print(f\"GPU devices found: {gpu_devices}\")\n",
    "\n",
    "# Check which GPU device is currently being used (if any)\n",
    "current_gpu_device = tf.test.gpu_device_name()\n",
    "if current_gpu_device:\n",
    "    print(f\"Current GPU device: {current_gpu_device}\")\n",
    "else:\n",
    "    print(\"No GPU device is currently being used.\")\n",
    "\n",
    "# Check if GPU acceleration is available for TensorFlow\n",
    "if tf.test.is_built_with_cuda():\n",
    "    print(\"TensorFlow is built with CUDA support (GPU acceleration).\")\n",
    "else:\n",
    "    print(\"TensorFlow is not built with CUDA support (GPU acceleration).\")\n",
    "\n",
    "    \n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_url = \"https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3\"\n",
    "encoder_url = \"https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/4\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marek Koolily hovorí s jasnejšími a faktami.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vyhýbal som sa parlamentným voľbám už veľmi dlho</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tak</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nech vás Boh žehná za prezidenta Zuzana Capputová</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Je to tiež osoba na správnom mieste.Ľudia nás ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0       Marek Koolily hovorí s jasnejšími a faktami.      0\n",
       "1   Vyhýbal som sa parlamentným voľbám už veľmi dlho      0\n",
       "2                                                Tak      0\n",
       "3  Nech vás Boh žehná za prezidenta Zuzana Capputová      0\n",
       "4  Je to tiež osoba na správnom mieste.Ľudia nás ...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sk_dataset/slovak_data4_preprocessed.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13158, 2), (13150, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split the train data according to their class\n",
    "off_df = df[df['label'] == 1]\n",
    "non_off_df = df[df['label'] == 0]\n",
    "off_df.shape, non_off_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the  metric result lists \n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "cv = 5  # Number of cross-validation folds\n",
    "kf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-09 15:36:33.861333: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-09 15:36:33.861534: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-09 15:36:33.861612: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-09 15:36:33.861733: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-09 15:36:33.861906: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-09 15:36:33.862094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2284 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Load the bert encoder model\n",
    "bert_preprocess = hub.load(preprocess_url)\n",
    "bert_encoder = hub.KerasLayer(encoder_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "def bert_based_model(dropout_rate=0.1):\n",
    "    # Bert layers\n",
    "    input_text = tf.keras.layers.Input(shape=(), dtype=tf.string, name='inputs')\n",
    "\n",
    "    # Create a KerasLayer for tokenization\n",
    "    tokenize = hub.KerasLayer(bert_preprocess.tokenize)\n",
    "    tokenized_inputs = tokenize(input_text)\n",
    "\n",
    "    tokenized_inputs.shape\n",
    "\n",
    "    # Pack input sequences for the Transformer encoder (if needed)\n",
    "    seq_length = 128  \n",
    "    bert_pack_inputs = hub.KerasLayer(\n",
    "        bert_preprocess.bert_pack_inputs,\n",
    "        arguments=dict(seq_length=seq_length))  # Optional argument.\n",
    "\n",
    "    encoder_inputs = bert_pack_inputs([tokenized_inputs])\n",
    "    outputs = bert_encoder(encoder_inputs)\n",
    "\n",
    "    # Neural network layers\n",
    "    #layer = tf.keras.layers.BatchNormalization()(layer)\n",
    "    layer = tf.keras.layers.Dropout(dropout_rate)(outputs[\"pooled_output\"])  # Dropout layer\n",
    "    layer = tf.keras.layers.Dense(128, activation=\"relu\")(layer)\n",
    "    #layer = tf.keras.layers.BatchNormalization()(layer)\n",
    "\n",
    "    layer = tf.keras.layers.Dropout(dropout_rate)(layer)  # Dropout layer\n",
    "    layer = tf.keras.layers.Dense(64, activation=\"relu\")(layer)\n",
    "\n",
    "    layer = tf.keras.layers.Dropout(dropout_rate)(layer)\n",
    "    layer = tf.keras.layers.Dense(32, activation=\"relu\")(layer)\n",
    "    #layer = tf.keras.layers.BatchNormalization()(layer)\n",
    "\n",
    "\n",
    "    layer = tf.keras.layers.Dropout(dropout_rate)(layer)\n",
    "\n",
    "    # Output layer for binary classification\n",
    "    output = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"output\")(layer)\n",
    "\n",
    "    # Use inputs and outputs to construct a final model\n",
    "    model = tf.keras.Model(inputs=[input_text ], outputs = [output])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-09 15:54:55.858021: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb2604b1080 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-09 15:54:55.858045: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2023-10-09 15:54:55.862802: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-09 15:54:55.876444: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "2023-10-09 15:54:55.934096: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - ETA: 0s - loss: 0.6022 - accuracy: 0.6507 - precision: 0.6110 - recall: 0.5897\n",
      "Epoch 1: loss improved from inf to 0.60216, saving model to checkpoints/checkpoints_mul/sk_checkpoint4/model_epoch_01--loss-0.6022.h5\n",
      "592/592 [==============================] - 234s 385ms/step - loss: 0.6022 - accuracy: 0.6507 - precision: 0.6110 - recall: 0.5897 - val_loss: 0.5668 - val_accuracy: 0.8171 - val_precision: 1.0000 - val_recall: 0.8171\n",
      "Epoch 2/5\n",
      "592/592 [==============================] - ETA: 0s - loss: 0.5468 - accuracy: 0.6902 - precision: 0.6221 - recall: 0.7727\n",
      "Epoch 2: loss improved from 0.60216 to 0.54677, saving model to checkpoints/checkpoints_mul/sk_checkpoint4/model_epoch_02--loss-0.5468.h5\n",
      "592/592 [==============================] - 229s 387ms/step - loss: 0.5468 - accuracy: 0.6902 - precision: 0.6221 - recall: 0.7727 - val_loss: 0.5722 - val_accuracy: 0.8665 - val_precision: 1.0000 - val_recall: 0.8665\n",
      "Epoch 3/5\n",
      "592/592 [==============================] - ETA: 0s - loss: 0.5338 - accuracy: 0.6950 - precision: 0.6206 - recall: 0.8077\n",
      "Epoch 3: loss improved from 0.54677 to 0.53383, saving model to checkpoints/checkpoints_mul/sk_checkpoint4/model_epoch_03--loss-0.5338.h5\n",
      "592/592 [==============================] - 229s 388ms/step - loss: 0.5338 - accuracy: 0.6950 - precision: 0.6206 - recall: 0.8077 - val_loss: 0.5463 - val_accuracy: 0.9069 - val_precision: 1.0000 - val_recall: 0.9069\n",
      "Epoch 4/5\n",
      "592/592 [==============================] - ETA: 0s - loss: 0.5231 - accuracy: 0.7053 - precision: 0.6294 - recall: 0.8200\n",
      "Epoch 4: loss improved from 0.53383 to 0.52312, saving model to checkpoints/checkpoints_mul/sk_checkpoint4/model_epoch_04--loss-0.5231.h5\n",
      "592/592 [==============================] - 230s 388ms/step - loss: 0.5231 - accuracy: 0.7053 - precision: 0.6294 - recall: 0.8200 - val_loss: 0.5358 - val_accuracy: 0.9515 - val_precision: 1.0000 - val_recall: 0.9515\n",
      "Epoch 5/5\n",
      "592/592 [==============================] - ETA: 0s - loss: 0.5195 - accuracy: 0.7085 - precision: 0.6352 - recall: 0.8092\n",
      "Epoch 5: loss improved from 0.52312 to 0.51946, saving model to checkpoints/checkpoints_mul/sk_checkpoint4/model_epoch_05--loss-0.5195.h5\n",
      "592/592 [==============================] - 230s 389ms/step - loss: 0.5195 - accuracy: 0.7085 - precision: 0.6352 - recall: 0.8092 - val_loss: 0.5496 - val_accuracy: 0.8580 - val_precision: 1.0000 - val_recall: 0.8580\n",
      "165/165 [==============================] - 57s 347ms/step - loss: 0.5094 - accuracy: 0.7300 - precision: 0.6806 - recall: 0.8670\n",
      "165/165 [==============================] - 57s 346ms/step\n",
      "Classification Report for Fold 1:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.82      0.59      0.69      2630\n",
      "     Class 1       0.68      0.87      0.76      2632\n",
      "\n",
      "    accuracy                           0.73      5262\n",
      "   macro avg       0.75      0.73      0.72      5262\n",
      "weighted avg       0.75      0.73      0.72      5262\n",
      "\n",
      "Epoch 1/5\n",
      "592/592 [==============================] - ETA: 0s - loss: 0.6077 - accuracy: 0.6419 - precision: 0.6021 - recall: 0.5733\n",
      "Epoch 1: loss improved from inf to 0.60773, saving model to checkpoints/checkpoints_mul/sk_checkpoint4/model_epoch_01--loss-0.6077.h5\n",
      "592/592 [==============================] - 231s 388ms/step - loss: 0.6077 - accuracy: 0.6419 - precision: 0.6021 - recall: 0.5733 - val_loss: 0.8010 - val_accuracy: 0.5012 - val_precision: 1.0000 - val_recall: 0.5012\n",
      "Epoch 2/5\n",
      "592/592 [==============================] - ETA: 0s - loss: 0.5471 - accuracy: 0.6889 - precision: 0.6212 - recall: 0.7694\n",
      "Epoch 2: loss improved from 0.60773 to 0.54707, saving model to checkpoints/checkpoints_mul/sk_checkpoint4/model_epoch_02--loss-0.5471.h5\n",
      "592/592 [==============================] - 230s 389ms/step - loss: 0.5471 - accuracy: 0.6889 - precision: 0.6212 - recall: 0.7694 - val_loss: 0.5047 - val_accuracy: 0.8988 - val_precision: 1.0000 - val_recall: 0.8988\n",
      "Epoch 3/5\n",
      "592/592 [==============================] - ETA: 0s - loss: 0.5355 - accuracy: 0.6924 - precision: 0.6201 - recall: 0.7954\n",
      "Epoch 3: loss improved from 0.54707 to 0.53549, saving model to checkpoints/checkpoints_mul/sk_checkpoint4/model_epoch_03--loss-0.5355.h5\n",
      "592/592 [==============================] - 230s 389ms/step - loss: 0.5355 - accuracy: 0.6924 - precision: 0.6201 - recall: 0.7954 - val_loss: 0.5943 - val_accuracy: 0.7990 - val_precision: 1.0000 - val_recall: 0.7990\n",
      "Epoch 4/5\n",
      "592/592 [==============================] - ETA: 0s - loss: 0.5269 - accuracy: 0.7012 - precision: 0.6240 - recall: 0.8247\n",
      "Epoch 4: loss improved from 0.53549 to 0.52691, saving model to checkpoints/checkpoints_mul/sk_checkpoint4/model_epoch_04--loss-0.5269.h5\n",
      "592/592 [==============================] - 230s 389ms/step - loss: 0.5269 - accuracy: 0.7012 - precision: 0.6240 - recall: 0.8247 - val_loss: 0.4838 - val_accuracy: 0.9601 - val_precision: 1.0000 - val_recall: 0.9601\n",
      "Epoch 5/5\n",
      "592/592 [==============================] - ETA: 0s - loss: 0.5222 - accuracy: 0.7013 - precision: 0.6228 - recall: 0.8318\n",
      "Epoch 5: loss improved from 0.52691 to 0.52225, saving model to checkpoints/checkpoints_mul/sk_checkpoint4/model_epoch_05--loss-0.5222.h5\n",
      "592/592 [==============================] - 230s 389ms/step - loss: 0.5222 - accuracy: 0.7013 - precision: 0.6228 - recall: 0.8318 - val_loss: 0.5503 - val_accuracy: 0.8684 - val_precision: 1.0000 - val_recall: 0.8684\n",
      "165/165 [==============================] - 57s 347ms/step - loss: 0.5093 - accuracy: 0.7349 - precision: 0.6844 - recall: 0.8723\n",
      "165/165 [==============================] - 57s 346ms/step\n",
      "Classification Report for Fold 2:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.82      0.60      0.69      2630\n",
      "     Class 1       0.68      0.87      0.77      2632\n",
      "\n",
      "    accuracy                           0.73      5262\n",
      "   macro avg       0.75      0.73      0.73      5262\n",
      "weighted avg       0.75      0.73      0.73      5262\n",
      "\n",
      "Epoch 1/5\n",
      "592/592 [==============================] - ETA: 0s - loss: 0.6050 - accuracy: 0.6471 - precision: 0.6058 - recall: 0.5903\n",
      "Epoch 1: loss improved from inf to 0.60505, saving model to checkpoints/checkpoints_mul/sk_checkpoint4/model_epoch_01--loss-0.6050.h5\n",
      "592/592 [==============================] - 231s 388ms/step - loss: 0.6050 - accuracy: 0.6471 - precision: 0.6058 - recall: 0.5903 - val_loss: 0.6121 - val_accuracy: 0.8062 - val_precision: 1.0000 - val_recall: 0.8062\n",
      "Epoch 2/5\n",
      "592/592 [==============================] - ETA: 0s - loss: 0.5454 - accuracy: 0.6923 - precision: 0.6217 - recall: 0.7864\n",
      "Epoch 2: loss improved from 0.60505 to 0.54542, saving model to checkpoints/checkpoints_mul/sk_checkpoint4/model_epoch_02--loss-0.5454.h5\n",
      "592/592 [==============================] - 229s 388ms/step - loss: 0.5454 - accuracy: 0.6923 - precision: 0.6217 - recall: 0.7864 - val_loss: 0.6348 - val_accuracy: 0.7762 - val_precision: 1.0000 - val_recall: 0.7762\n",
      "Epoch 3/5\n",
      "592/592 [==============================] - ETA: 0s - loss: 0.5319 - accuracy: 0.6996 - precision: 0.6249 - recall: 0.8115\n",
      "Epoch 3: loss improved from 0.54542 to 0.53187, saving model to checkpoints/checkpoints_mul/sk_checkpoint4/model_epoch_03--loss-0.5319.h5\n",
      "592/592 [==============================] - 230s 389ms/step - loss: 0.5319 - accuracy: 0.6996 - precision: 0.6249 - recall: 0.8115 - val_loss: 0.4963 - val_accuracy: 0.9012 - val_precision: 1.0000 - val_recall: 0.9012\n",
      "Epoch 4/5\n",
      "592/592 [==============================] - ETA: 0s - loss: 0.5238 - accuracy: 0.7057 - precision: 0.6298 - recall: 0.8201\n",
      "Epoch 4: loss improved from 0.53187 to 0.52376, saving model to checkpoints/checkpoints_mul/sk_checkpoint4/model_epoch_04--loss-0.5238.h5\n",
      "592/592 [==============================] - 230s 388ms/step - loss: 0.5238 - accuracy: 0.7057 - precision: 0.6298 - recall: 0.8201 - val_loss: 0.6835 - val_accuracy: 0.6926 - val_precision: 1.0000 - val_recall: 0.6926\n",
      "Epoch 5/5\n",
      "592/592 [==============================] - ETA: 0s - loss: 0.5217 - accuracy: 0.7019 - precision: 0.6278 - recall: 0.8093\n",
      "Epoch 5: loss improved from 0.52376 to 0.52170, saving model to checkpoints/checkpoints_mul/sk_checkpoint4/model_epoch_05--loss-0.5217.h5\n",
      "592/592 [==============================] - 230s 389ms/step - loss: 0.5217 - accuracy: 0.7019 - precision: 0.6278 - recall: 0.8093 - val_loss: 0.5614 - val_accuracy: 0.7948 - val_precision: 1.0000 - val_recall: 0.7948\n",
      "165/165 [==============================] - 57s 347ms/step - loss: 0.5142 - accuracy: 0.7193 - precision: 0.6872 - recall: 0.8055\n",
      "165/165 [==============================] - 57s 345ms/step\n",
      "Classification Report for Fold 3:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.76      0.63      0.69      2630\n",
      "     Class 1       0.69      0.81      0.74      2632\n",
      "\n",
      "    accuracy                           0.72      5262\n",
      "   macro avg       0.73      0.72      0.72      5262\n",
      "weighted avg       0.73      0.72      0.72      5262\n",
      "\n",
      "Epoch 1/5\n",
      "592/592 [==============================] - ETA: 0s - loss: 0.6165 - accuracy: 0.6429 - precision: 0.6092 - recall: 0.5487\n",
      "Epoch 1: loss improved from inf to 0.61646, saving model to checkpoints/checkpoints_mul/sk_checkpoint4/model_epoch_01--loss-0.6165.h5\n",
      "592/592 [==============================] - 231s 388ms/step - loss: 0.6165 - accuracy: 0.6429 - precision: 0.6092 - recall: 0.5487 - val_loss: 0.8325 - val_accuracy: 0.4784 - val_precision: 1.0000 - val_recall: 0.4784\n",
      "Epoch 2/5\n",
      "592/592 [==============================] - ETA: 0s - loss: 0.5503 - accuracy: 0.6910 - precision: 0.6268 - recall: 0.7539\n",
      "Epoch 2: loss improved from 0.61646 to 0.55031, saving model to checkpoints/checkpoints_mul/sk_checkpoint4/model_epoch_02--loss-0.5503.h5\n",
      "592/592 [==============================] - 230s 388ms/step - loss: 0.5503 - accuracy: 0.6910 - precision: 0.6268 - recall: 0.7539 - val_loss: 0.5524 - val_accuracy: 0.9188 - val_precision: 1.0000 - val_recall: 0.9188\n",
      "Epoch 3/5\n",
      "592/592 [==============================] - ETA: 0s - loss: 0.5358 - accuracy: 0.6985 - precision: 0.6233 - recall: 0.8136\n",
      "Epoch 3: loss improved from 0.55031 to 0.53582, saving model to checkpoints/checkpoints_mul/sk_checkpoint4/model_epoch_03--loss-0.5358.h5\n",
      "592/592 [==============================] - 230s 388ms/step - loss: 0.5358 - accuracy: 0.6985 - precision: 0.6233 - recall: 0.8136 - val_loss: 0.6199 - val_accuracy: 0.8304 - val_precision: 1.0000 - val_recall: 0.8304\n",
      "Epoch 4/5\n",
      "592/592 [==============================] - ETA: 0s - loss: 0.5269 - accuracy: 0.7073 - precision: 0.6317 - recall: 0.8190\n",
      "Epoch 4: loss improved from 0.53582 to 0.52693, saving model to checkpoints/checkpoints_mul/sk_checkpoint4/model_epoch_04--loss-0.5269.h5\n",
      "592/592 [==============================] - 230s 388ms/step - loss: 0.5269 - accuracy: 0.7073 - precision: 0.6317 - recall: 0.8190 - val_loss: 0.7343 - val_accuracy: 0.5188 - val_precision: 1.0000 - val_recall: 0.5188\n",
      "Epoch 5/5\n",
      "592/592 [==============================] - ETA: 0s - loss: 0.5255 - accuracy: 0.7027 - precision: 0.6254 - recall: 0.8262\n",
      "Epoch 5: loss improved from 0.52693 to 0.52552, saving model to checkpoints/checkpoints_mul/sk_checkpoint4/model_epoch_05--loss-0.5255.h5\n",
      "592/592 [==============================] - 230s 388ms/step - loss: 0.5255 - accuracy: 0.7027 - precision: 0.6254 - recall: 0.8262 - val_loss: 0.5001 - val_accuracy: 0.8893 - val_precision: 1.0000 - val_recall: 0.8893\n",
      "165/165 [==============================] - 57s 347ms/step - loss: 0.5065 - accuracy: 0.7293 - precision: 0.6710 - recall: 0.9000\n",
      "165/165 [==============================] - 57s 345ms/step\n",
      "Classification Report for Fold 4:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.85      0.56      0.67      2630\n",
      "     Class 1       0.67      0.90      0.77      2631\n",
      "\n",
      "    accuracy                           0.73      5261\n",
      "   macro avg       0.76      0.73      0.72      5261\n",
      "weighted avg       0.76      0.73      0.72      5261\n",
      "\n",
      "Epoch 1/5\n",
      "592/592 [==============================] - ETA: 0s - loss: 0.6057 - accuracy: 0.6501 - precision: 0.6127 - recall: 0.5793\n",
      "Epoch 1: loss improved from inf to 0.60570, saving model to checkpoints/checkpoints_mul/sk_checkpoint4/model_epoch_01--loss-0.6057.h5\n",
      "592/592 [==============================] - 232s 388ms/step - loss: 0.6057 - accuracy: 0.6501 - precision: 0.6127 - recall: 0.5793 - val_loss: 0.7507 - val_accuracy: 0.5819 - val_precision: 1.0000 - val_recall: 0.5819\n",
      "Epoch 2/5\n",
      "592/592 [==============================] - ETA: 0s - loss: 0.5431 - accuracy: 0.6915 - precision: 0.6248 - recall: 0.7664\n",
      "Epoch 2: loss improved from 0.60570 to 0.54307, saving model to checkpoints/checkpoints_mul/sk_checkpoint4/model_epoch_02--loss-0.5431.h5\n",
      "592/592 [==============================] - 230s 388ms/step - loss: 0.5431 - accuracy: 0.6915 - precision: 0.6248 - recall: 0.7664 - val_loss: 0.5657 - val_accuracy: 0.8176 - val_precision: 1.0000 - val_recall: 0.8176\n",
      "Epoch 3/5\n",
      "592/592 [==============================] - ETA: 0s - loss: 0.5339 - accuracy: 0.6963 - precision: 0.6239 - recall: 0.7981\n",
      "Epoch 3: loss improved from 0.54307 to 0.53393, saving model to checkpoints/checkpoints_mul/sk_checkpoint4/model_epoch_03--loss-0.5339.h5\n",
      "592/592 [==============================] - 230s 388ms/step - loss: 0.5339 - accuracy: 0.6963 - precision: 0.6239 - recall: 0.7981 - val_loss: 0.5371 - val_accuracy: 0.8713 - val_precision: 1.0000 - val_recall: 0.8713\n",
      "Epoch 4/5\n",
      "592/592 [==============================] - ETA: 0s - loss: 0.5279 - accuracy: 0.6987 - precision: 0.6242 - recall: 0.8097\n",
      "Epoch 4: loss improved from 0.53393 to 0.52792, saving model to checkpoints/checkpoints_mul/sk_checkpoint4/model_epoch_04--loss-0.5279.h5\n",
      "592/592 [==============================] - 230s 388ms/step - loss: 0.5279 - accuracy: 0.6987 - precision: 0.6242 - recall: 0.8097 - val_loss: 0.3308 - val_accuracy: 0.9848 - val_precision: 1.0000 - val_recall: 0.9848\n",
      "Epoch 5/5\n",
      "592/592 [==============================] - ETA: 0s - loss: 0.5210 - accuracy: 0.7040 - precision: 0.6262 - recall: 0.8294\n",
      "Epoch 5: loss improved from 0.52792 to 0.52099, saving model to checkpoints/checkpoints_mul/sk_checkpoint4/model_epoch_05--loss-0.5210.h5\n",
      "592/592 [==============================] - 230s 388ms/step - loss: 0.5210 - accuracy: 0.7040 - precision: 0.6262 - recall: 0.8294 - val_loss: 0.5054 - val_accuracy: 0.8865 - val_precision: 1.0000 - val_recall: 0.8865\n",
      "165/165 [==============================] - 57s 347ms/step - loss: 0.5062 - accuracy: 0.7291 - precision: 0.6727 - recall: 0.8928\n",
      "165/165 [==============================] - 57s 346ms/step\n",
      "Classification Report for Fold 5:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.84      0.57      0.68      2630\n",
      "     Class 1       0.67      0.89      0.77      2631\n",
      "\n",
      "    accuracy                           0.73      5261\n",
      "   macro avg       0.76      0.73      0.72      5261\n",
      "weighted avg       0.76      0.73      0.72      5261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "X = df['tweet'].values  \n",
    "y = df['label'].values  \n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Compile the model\n",
    "    model = bert_based_model()\n",
    "\n",
    "    # Compile and train the model\n",
    "    checkpoint_dir = \"checkpoints/checkpoints_mul/sk_checkpoint4\"\n",
    "\n",
    "    # creates the folder if not exist\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir, mode = 0o777)\n",
    "\n",
    "    checkpoint_file_format = os.path.join(checkpoint_dir, \"model_epoch_{epoch:02d}--loss-{loss:.4f}.h5\")\n",
    "\n",
    "    # Create a ModelCheckpoint callback\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_file_format,\n",
    "        save_weights_only=True,  # Save only the model's weights\n",
    "        save_best_only=True,     # Save the best one\n",
    "        monitor=\"loss\",          # Monitor loss\n",
    "        mode=\"auto\",             # Auto-detect whether to minimize or maximize the monitored metric\n",
    "        verbose=1)               # Show progress during training\n",
    "\n",
    "    #Compile the model\n",
    "    METRICS = [\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=METRICS)\n",
    "                 \n",
    "\n",
    "    model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.1, callbacks=[model_checkpoint_callback])\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    eval_metrics = model.evaluate(X_test, y_test)\n",
    "\n",
    "    accuracy_scores.append(eval_metrics[1])  # Accuracy\n",
    "    precision_scores.append(eval_metrics[2])  # Precision\n",
    "    recall_scores.append(eval_metrics[3])     # Recall\n",
    "    f1_scores.append(2 * (eval_metrics[2] * eval_metrics[3]) / (eval_metrics[2] + eval_metrics[3]))  # F1-score\n",
    "\n",
    "    # Generate and print the classification report\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = y_pred.flatten()\n",
    "    y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "    classification_rep = classification_report(y_test, y_pred, target_names=['Class 0', 'Class 1'])\n",
    "    print(f\"Classification Report for Fold {len(accuracy_scores)}:\\n\", classification_rep)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.7285237073898315\n",
      "Standard Deviation Accuracy: 0.0050702746010004305\n",
      "Mean Precision: 0.6791648983955383\n",
      "Standard Deviation Precision: 0.006355212046746722\n",
      "Mean Recall: 0.8675374507904052\n",
      "Standard Deviation Recall: 0.03337926529584058\n",
      "Mean F1-Score: 0.7614636281781952\n",
      "Standard Deviation F1-Score: 0.010124273970846417\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean Accuracy: {np.mean(accuracy_scores)}')\n",
    "print(f'Standard Deviation Accuracy: {np.std(accuracy_scores)}')\n",
    "\n",
    "print(f'Mean Precision: {np.mean(precision_scores)}')\n",
    "print(f'Standard Deviation Precision: {np.std(precision_scores)}')\n",
    "\n",
    "print(f'Mean Recall: {np.mean(recall_scores)}')\n",
    "print(f'Standard Deviation Recall: {np.std(recall_scores)}')\n",
    "\n",
    "print(f'Mean F1-Score: {np.mean(f1_scores)}')\n",
    "print(f'Standard Deviation F1-Score: {np.std(f1_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.02600755],\n",
       "       [0.00612317],\n",
       "       [0.00174148],\n",
       "       [0.65219176],\n",
       "       [0.523427  ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slovak_sentences = [\n",
    "    \"Dnes je krásny slnečný deň.\",\n",
    "    \"Včera som čítal knihu v parku.\",\n",
    "    \"Obľubujem dlhé prechádzky v prírode.\",\n",
    "    \"toto je hlúpa lekcia\",\n",
    "    \"nenávidím ťa vidieť plakať\"\n",
    "]\n",
    "model.predict(slovak_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
